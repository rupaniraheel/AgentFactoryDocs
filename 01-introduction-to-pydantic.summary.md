### Core Concept

Runtime data validation bridges the gap between type hints (documentation) and actual data enforcement. Pydantic models automatically validate input data against declared schemas, catching type errors and constraint violations at the boundary before bad data enters your system—critical for AI-native development where external data (AI outputs, API responses, user input) must be trusted through validation, not faith.

### Key Mental Models

**The Type Hint Illusion**: Python type hints document what SHOULD be (reader intention), but don't enforce what IS (runtime reality). `name: str` tells developers "this should be a string," but Python accepts `name=123` at runtime. Pydantic flips this: declaring `name: str` in a BaseModel GUARANTEES name is a string or validation fails.

**Validation as Safety Net**: Think of Pydantic as your application's immune system—it inspects data entering the system and rejects anything malformed. This separates concerns: your code assumes valid data; Pydantic ensures it is.

**Nested Validation Cascade**: When you declare `authors: list[Author]` where Author is a Pydantic model, validation flows through all nested layers. Pydantic validates each Author in the list and reports all errors simultaneously—not just the first one.

### Critical Patterns

**BaseModel as Specification**: Inherit from `BaseModel` to make validation active. Regular Python classes with type hints do NO validation. `class Book(BaseModel)` activates automatic runtime checking; `class Book` does not.

**Optional with Default**: `field: str | None = None` means the field can be absent or contain None, using None as default. Without the default, the field is required.

**ValidationError Exception Structure**: Catch `ValidationError` to access detailed error information via `.errors()`, which returns a list of dicts with `loc` (field path), `msg` (human message), and `type` (error classification). This enables sophisticated error handling and user feedback.

### AI Collaboration Keys

When working with AI systems, Pydantic models serve as contracts: define a model, ask Claude Code to generate JSON matching it, then validate the output. Invalid JSON reveals prompt clarity issues—use error messages to iteratively improve prompts. This validation-driven iteration is the foundation of reliable AI-native systems.

### Common Mistakes

**Forgetting BaseModel inheritance** creates silent failures—your code thinks validation happened but it didn't. Always verify the inheritance chain.

**Not handling ValidationError** crashes your application. Wrap model instantiation in try-except blocks, especially for untrusted input.

**Ambiguous type hints** like `tags: list` (no element type) prevent Pydantic from validating list contents. Always use `list[str]`, not `list`, to enable element validation.

### Connections

Builds on: Chapter 30 (dataclasses, classes), basic type hints (Chapter 20)

Enables: Chapter 5 (advanced validators, Field constraints), Chapter 31 Lesson 5 (AI output validation), FastAPI request validation, configuration management systems
